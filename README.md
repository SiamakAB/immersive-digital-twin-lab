# Immersive Digital Twin Lab
üåê Exploring immersive, AI-augmented, and cloud-based digital twins for architecture, urban systems, and collaborative design.

<p align="center">
  <img src="assets/immersive-digital-twin-lab-banner.png" width="1000" alt="Immersive Digital Twin Lab Banner">
</p>

## Overview
The **Immersive Digital Twin Lab** is established at the **University of Oulu**, within the **Department of Technology** and **WE3 Unit**, as part of the **Digital Waters Flagship** program. The lab focuses on **virtualising digital twins** and making them accessible through **immersive XR-based experiences**, supporting stakeholder collaboration and co-creation of services.

Our mission is to enable **scalable, interoperable, and collaborative digital twin experiences** through **open-source technologies**, **cloud platforms**, **XR interfaces**, and **data-driven workflows**.

## Core Objectives

1. **Virtualising Digital Twins for immersive experiences**
   - Transform digital twins from technical models into interactive, human-centered platforms
   - Integrate XR (AR/VR/MR) for real-time visualization and interaction
   - Support collaborative decision-making and stakeholder engagement

2. **Enable interoperable and scalable digital solutions**
   - Build cloud-based, modular architectures
   - Integrate IoT and sensor networks with real-time simulation pipelines
   - Promote **FAIR** (Findable, Accessible, Interoperable, Reusable) principles
   - Foster collaboration across disciplines ‚Äî from architecture, engineering, and construction to urban planning

## Organizational Structure
The lab operates primarily under **RT4: Digital Services, Platforms, and Business Applications**, in collaboration with other research themes.

| RT4: Digital services, platforms, and business applications | Interoperable digital solutions for sharing and exploring data, and co-creation of services |

### XR Services

| XR Service | Description |
|------------|-------------|
| DT Integration | Connect VR app to DIWA Digital Twin backend for synchronized model & sensor data. |
| WebGIS Interop | Seamless integration with ArcGIS Pro, Enterprise, and Online; 2D dashboards ‚Üî 3D immersive exploration. |
| 3D Sim & Design | Immersive VR environments in Unity, Cesium, and ArcGIS SDKs for city-scale hydrological & spatial simulations. |
| Collaborative VR | Multi-user VR sessions for co-exploration, participatory planning, and stakeholder engagement. |
| AI Assistant | Generative AI assistants for natural-language queries, scenario explanations, and interactive model exploration. |

*The Immersive Digital Twin Lab leverages these XR services to demonstrate and explore supersites and real-world use cases. XR demonstrations will initially be conducted in **VR environments** (3DoF, 6DoF, tabletop, 1:1 scale) to provide fully immersive, interactive experiences. Subsequently, these experiences will be extended to **Mixed Reality (MR) and Augmented Reality (AR) devices**, enabling multi-scale visualization, collaborative exploration, and stakeholder engagement across diverse digital twin scenarios.*

| RT5: Stakeholder Collaboration | Methods and platforms for collaborative design, immersive co-creation, and multi-user interaction |
| Training & Capacity Building | Workshops, tutorials, and hands-on sessions to train students and researchers in XR and digital twin technologies |

## Key Technologies
We build upon **open, scalable, and interoperable architectures**, including:

- **Game & XR Engines:** Unity3D, Unreal Engine  
- **GIS & Digital Twin Platforms:** ArcGIS Pro, ArcGIS Enterprise, ArcGIS Online, QGIS 
- **Cloud Platforms:** AWS, Azure for XR visualization and real-time data streaming  
- **XR Devices & Interfaces:** HoloLens 2, Meta Quest 3, Magic Leap 2, WebXR

## Getting Started
Learn about our **Immersive Digital Twin Lab architectures and XR workflows**:

- Explore XR-enabled digital twin environments  
- Access modular data and model pipelines  
- Follow standards for reproducible repository and project management  

## Access the Immersive Digital Twin Lab
- **IDT Lab:** Email `siamak.bazzaz@oulu.fi` to request access  
- **Share and publish data:** Upload models, scans, and XR assets for collaborative use (coming soon)

## Explore our repositories (coming soon)
Visit our **public repositories** to discover ongoing XR and digital twin projects 

## Join the Discussion (coming soon)
Participate in our **GitHub Discussions** to collaborate on immersive digital twin topics (coming soon)

## Contribute (coming soon)
- Review our **Contributing Guidelines**  
- Read the **Code of Conduct**  
- Open issues, propose features, or submit pull requests  
- Collaborate on **digital twin and XR use cases**

## Additional Resources

- **Data requirements for immersive demonstrations**  
  For information on the types of data to be shared with the Immersive Digital Twin Lab for XR-based demonstrations, please refer to  
  üëâ [`docs/data-requirements.md`](docs/data-requirements.md)

- **Proposed XR roadmap and future planning**  
  For the planned/proposed XR development roadmap and long-term objectives for XR integration, please see  
  üëâ [`docs/xr-roadmap.md`](docs/xr-roadmap.md)

- **XR Activities and Implementation**  
  For concrete activities supporting the XR roadmap‚Äîincluding workshops, newsletters, demo days, online courses, and infrastructure development‚Äîplease see  
  üëâ [`docs/xr-activities.md`](docs/xr-activities.md)

- **Digital Waters GitHub organization**  
  To explore repositories, tools, and digital twin initiatives developed within the Digital Waters Flagship, visit  
  üëâ [DigitalWaters-fi on GitHub](https://github.com/DigitalWaters-fi)

## Citation & Attribution (coming soon)
If you use our frameworks, models, or XR platforms in your research, please cite the repository via Zenodo. For publications and methodology details, see our **publications page**.

## Contact
Questions, suggestions, or collaboration inquiries are welcome: `siamak.bazzaz@oulu.fi`

---

‚ö†Ô∏è **This page is under construction** and will be officially launched in **February 2026**. All ideas, suggestions, and feedback are welcome ‚Äî your contributions are highly appreciated!
